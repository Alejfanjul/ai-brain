# Plano: Memory Lane System (baseado no JFDI do Hillman)

> **Contexto:** Este plano implementa o **Marco 3: Mem√≥ria e S√≠ntese** do documento [`ai_brain_parceiro_digital-v0.5.md`](./ai_brain_parceiro_digital-v0.5.md).
>
> Marcos anteriores j√° foram conclu√≠dos:
> - ‚úÖ Marco 1: Audit Trail (hooks + Supabase)
> - ‚úÖ Marco 2: Persist√™ncia de Conversas (81 sess√µes, 1000+ mensagens salvas)

## Objetivo
Implementar sistema de mem√≥ria sem√¢ntica que **cruza mem√≥rias das conversas com conte√∫dos capturados (sources)**, permitindo relacionar planos de projetos com ideias de autores como Nate, Hillman, Seth Godin, etc.

## Decis√µes do usu√°rio
- **Embeddings:** Ollama (local, gratuito) - modelo nomic-embed-text (768 dim)
- **Frequ√™ncia:** 5 min sync sess√µes, 15 min extra√ß√£o mem√≥rias
- **Interface:** Scripts Python primeiro (validar antes de automatizar)
- **Scheduler:** Cron (simples)
- **Chunks:** ~600 palavras com 15% overlap
- **Metadados:** Extrair autor/data do nome do arquivo

---

## Status de Implementa√ß√£o

| Fase | Status | Data |
|------|--------|------|
| Fase 1: Sync Peri√≥dico + Extra√ß√£o | ‚úÖ Conclu√≠da | 2026-01-05 |
| Fase 2: Embeddings das mem√≥rias | ‚úÖ Conclu√≠da | 2026-01-06 |
| Fase 2.5: Embeddings dos sources | üîÑ Em progresso | 2026-01-08 |
| Fase 3: Script de busca unificada | üìã Pendente | - |
| Fase 4: Hooks de Retrieval | üìã Pendente | - |
| Fase 5: Surprise Triggers | üìã Pendente | - |
| Fase 6: Feedback Loop | üìã Pendente | - |
| Fase 7: Auto-Atualiza√ß√£o de Planos | üìã Pendente | - |

### Resultados da Fase 1
- **22 mem√≥rias extra√≠das** das conversas existentes
- Tipos: 8 workflows, 6 decis√µes, 6 insights, 1 corre√ß√£o, 1 padr√£o
- Cron jobs configurados e funcionando

### Resultados da Fase 2
- **40 mem√≥rias com embeddings** (768 dimens√µes via nomic-embed-text)
- Script `generate_embeddings.py` criado e funcionando
- Ollama instalado e configurado localmente
- √çndice IVFFlat pendente (criar via Supabase Dashboard)

---

## Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      MEMORY LANE SYSTEM                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                  ‚îÇ
‚îÇ   CRON JOBS (‚úÖ ATIVO)                CLAUDE CODE HOOKS (pendente)‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ   ‚îÇ */5 min          ‚îÇ               ‚îÇ user_prompt_submit‚îÇ       ‚îÇ
‚îÇ   ‚îÇ sync_sessions.py ‚îÇ               ‚îÇ ‚Üí busca mem√≥rias ‚îÇ       ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ ‚Üí injeta contexto‚îÇ       ‚îÇ
‚îÇ            ‚îÇ                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ   ‚îÇ */15 min         ‚îÇ               ‚îÇ tool_use (file)  ‚îÇ       ‚îÇ
‚îÇ   ‚îÇ extract_memories ‚îÇ               ‚îÇ ‚Üí mem√≥rias de    ‚îÇ       ‚îÇ
‚îÇ   ‚îÇ .py              ‚îÇ               ‚îÇ   arquivos       ‚îÇ       ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ            ‚îÇ                                  ‚îÇ                  ‚îÇ
‚îÇ            v                                  v                  ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ   ‚îÇ              SUPABASE + PGVECTOR (‚úÖ ATIVO)          ‚îÇ       ‚îÇ
‚îÇ   ‚îÇ  conversas ‚îÇ mensagens ‚îÇ memorias ‚îÇ entidades        ‚îÇ       ‚îÇ
‚îÇ   ‚îÇ            ‚îÇ           ‚îÇ          ‚îÇ                  ‚îÇ       ‚îÇ
‚îÇ   ‚îÇ  embedding vector(768) via Ollama nomic-embed-text   ‚îÇ       ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Fases de Implementa√ß√£o

### ‚úÖ Fase 1: Sync Peri√≥dico + Extra√ß√£o B√°sica (CONCLU√çDA)

**Arquivos criados/modificados:**
- ‚úÖ `~/.claude/hooks/sync_sessions.py` - modo --cron adicionado
- ‚úÖ `~/ai-brain/scripts/extract_memories.py` - extra√ß√£o via Claude Haiku
- ‚úÖ `~/ai-brain/scripts/supabase_schema_v4.sql` - schema com pgvector

**Tarefas conclu√≠das:**
1. ‚úÖ Instalar Ollama: `curl -fsSL https://ollama.com/install.sh | sh`
2. ‚úÖ Baixar modelo: `ollama pull nomic-embed-text`
3. ‚úÖ Modificar sync_sessions.py para rodar via cron (incremental)
4. ‚úÖ Criar extract_memories.py com prompt de extra√ß√£o
5. ‚úÖ Configurar cron jobs
6. ‚úÖ Executar schema v4 no Supabase
7. ‚úÖ Configurar ANTHROPIC_API_KEY no .env

### ‚úÖ Fase 2: Embeddings das mem√≥rias (CONCLU√çDA)

**Arquivos criados:**
- ‚úÖ `~/ai-brain/scripts/generate_embeddings.py` - gera√ß√£o via Ollama

**Tarefas conclu√≠das:**
1. ‚úÖ Habilitar pgvector no Supabase (j√° estava no schema v4)
2. ‚úÖ Instalar Ollama e modelo nomic-embed-text
3. ‚úÖ Criar script que gera embeddings via Ollama
4. ‚úÖ Processar 40 mem√≥rias existentes
5. üìã Criar √≠ndice IVFFlat (pendente - rodar no Supabase Dashboard)

**SQL para criar √≠ndice (rodar no Supabase Dashboard > SQL Editor):**
```sql
CREATE INDEX IF NOT EXISTS idx_memorias_embedding ON memorias
    USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
```

**Contexto da conversa 2026-01-06:**
Durante a implementa√ß√£o, discutimos o artigo "Context Engineering for AI Agents" do Manus.
Decis√£o: AI Brain √© a funda√ß√£o (mem√≥ria + contexto) para futuros sistemas agentic.

### üîÑ Fase 2.5: Embeddings dos sources (EM PROGRESSO)

> **Decis√£o 2026-01-08:** Priorizar embeddings dos sources para permitir cruzamento entre mem√≥rias (conversas) e conte√∫dos capturados (transcripts, artigos). Isso permite responder perguntas como "como nosso plano se relaciona com as ideias do Nate?"

**Nova tabela no Supabase:**
```sql
CREATE TABLE source_chunks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    source_file TEXT,        -- ex: "2026-01-06-nate-..."
    autor TEXT,              -- ex: "nate", "hillman"
    chunk_index INTEGER,     -- posi√ß√£o no arquivo
    content TEXT,            -- o texto do chunk
    embedding VECTOR(768),
    criado_em TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_source_chunks_embedding ON source_chunks
    USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
```

**Arquivos a criar:**
- `~/ai-brain/scripts/embed_sources.py` - processa arquivos em sources/

**Tarefas:**
1. Criar tabela source_chunks no Supabase
2. Criar script embed_sources.py:
   - L√™ cada arquivo em `sources/`
   - Extrai metadados (autor, data) do nome do arquivo
   - Quebra em chunks de ~600 palavras com 15% overlap
   - Gera embedding via Ollama
   - Salva no Supabase
3. Processar os 68+ arquivos existentes

**Configura√ß√µes definidas:**
- Tamanho chunk: ~600 palavras
- Overlap: 15% (~90 palavras)
- Extra√ß√£o de autor: autom√°tica do nome do arquivo

**Progresso (2026-01-08):**
- ‚úÖ Tabela `source_chunks` criada no Supabase
- ‚úÖ Script `embed_sources.py` criado e funcionando
- üîÑ **218/910 chunks** processados (~24%)
- ‚è∏Ô∏è Pausado para continuar em m√°quina com GPU (RTX 5060)
- Ver instru√ß√µes em `CLAUDE.md` se√ß√£o "Continuar processamento na m√°quina com RTX"

### üìã Fase 3: Script de busca unificada (PENDENTE)

> **Decis√£o 2026-01-08:** Fazer busca manual via script primeiro, antes de automatizar com hooks. Permite validar a qualidade da busca sem√¢ntica.

**Arquivos a criar:**
- `~/ai-brain/scripts/search.py` - busca unificada

**Tarefas:**
1. Criar script que:
   - Recebe query como argumento
   - Gera embedding da query via Ollama
   - Busca em `memorias` (conversas)
   - Busca em `source_chunks` (conte√∫dos)
   - Retorna resultados combinados com score
2. Permitir filtros opcionais (autor, tipo, data)

**Exemplo de uso:**
```bash
python3 scripts/search.py "como implementar agentes ia"
python3 scripts/search.py "ideias do nate sobre automa√ß√£o" --autor nate
```

### üìã Fase 4: Hooks de Retrieval (PENDENTE)

**Arquivos a criar:**
- `~/.claude/hooks/memory_retrieval_hook.py`
- `~/.claude/hooks/file_memory_hook.py`

**Tarefas:**
1. Hook user_prompt_submit ‚Üí busca mem√≥rias/sources ‚Üí injeta contexto
2. Hook tool_use (Edit/Write/Read) ‚Üí mem√≥rias de arquivo
3. Algoritmo de retrieval (entidades + sem√¢ntico + filtros)

**Pr√©-requisito:** Fase 3 conclu√≠da e validada

### üìã Fase 5: Surprise Triggers (PENDENTE)

**Tarefas:**
1. Detectar recovery patterns (erro ‚Üí sucesso)
2. Detectar corre√ß√µes do usu√°rio
3. Detectar entusiasmo ("perfeito!", "exatamente!")
4. Detectar rea√ß√µes negativas ("nunca fa√ßa isso")
5. Boost no surprise_score das mem√≥rias

### üìã Fase 6: Feedback Loop (PENDENTE)

**Tarefas:**
1. Registrar quais mem√≥rias foram surfaceadas
2. Coletar feedback (√∫til/n√£o √∫til)
3. Re-ranking baseado em feedback (+/-5% por voto)

### üìã Fase 7: Auto-Atualiza√ß√£o de Planos (PENDENTE)

**Objetivo:** Sistema analisa conversas e atualiza automaticamente arquivos de planejamento.

**Arquivos a criar:**
- `~/ai-brain/scripts/update_plans.py`

**Tarefas:**
1. Analisar conversas em busca de:
   - Decis√µes tomadas (atualizar status de itens)
   - Novos itens identificados (adicionar ao roadmap)
   - Mudan√ßas de escopo (ajustar descri√ß√µes)
   - Conclus√µes de tarefas (marcar como ‚úÖ)
2. Gerar diff proposto antes de aplicar mudan√ßas
3. Aplicar mudan√ßas nos arquivos `.md` de planejamento
4. Commitar automaticamente com mensagem descritiva

**Arquivos monitorados:**
- `projects/ai-brain/ai_brain_parceiro_digital-v*.md`
- `projects/ai-brain/memory_lane_plan.md`
- `projects/*/README.md`

**Frequ√™ncia:** Di√°ria ou ao final de sess√µes significativas

**Insight:** Isso fecha o loop - o sistema n√£o s√≥ aprende das conversas, mas mant√©m sua pr√≥pria documenta√ß√£o atualizada.

---

## Cron Setup (‚úÖ ATIVO)

```crontab
# Memory Lane System - AI Brain
# Session sync - cada 5 minutos
*/5 * * * * python3 ~/.claude/hooks/sync_sessions.py --cron >> /tmp/ml_sync.log 2>&1

# Extra√ß√£o de mem√≥rias - cada 15 minutos
*/15 * * * * python3 ~/ai-brain/scripts/extract_memories.py >> /tmp/ml_extract.log 2>&1
```

**Logs:**
- Sync: `/tmp/ml_sync.log`
- Extra√ß√£o: `/tmp/ml_extract.log`

---

## Tipos de Mem√≥ria

| Tipo | Descri√ß√£o | Exemplo |
|------|-----------|---------|
| decisao | Escolha feita | "Decidimos usar Supabase ao inv√©s de Firebase" |
| insight | Realiza√ß√£o | "Descobri que hooks rodam antes do output" |
| padrao | Comportamento repetido | "Sempre commitar antes de push" |
| aprendizado | Conhecimento novo | "pgvector usa cosine similarity" |
| correcao | Erro corrigido | "UUID precisa de aspas no SQL" |
| workflow | Sequ√™ncia de a√ß√µes | "Para deploy: test ‚Üí build ‚Üí push" |
| gap | Desconex√£o identificada | "Sistema X e Y n√£o conversam" |

---

## Configura√ß√£o Necess√°ria

### .env (~/ai-brain/.env)
```
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_ANON_KEY=eyJ...
ANTHROPIC_API_KEY=sk-ant-api03-...
```

### Depend√™ncias
- Python 3.x (j√° instalado)
- Ollama com modelo `nomic-embed-text`
- Supabase com schema v4 executado

---

## Refer√™ncias
- [Documento principal do AI Brain](./ai_brain_parceiro_digital-v0.4.md)
- [Alex Hillman - Memory Lane](https://www.youtube.com/watch?v=Wpz7LNI737Q)
- [JFDI System](../../sources/2025-12-13-alex-hillman-jfdi-system-my-ai-executive-assistant-full-life-co.md)
