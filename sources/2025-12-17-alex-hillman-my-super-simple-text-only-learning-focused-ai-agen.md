# my super simple, text-only, learning-focused ai agent memory system (no embeddings needed)

## Fonte
- **Tipo:** video
- **Autor:** Alex Hillman
- **URL:** https://www.youtube.com/watch?v=vWRwa9GMM00
- **Duração:** 21 min
- **Data original:** 2025-12-17
- **Data captura:** 2026-01-04

## Conteúdo

Kind: captions Language: en One of the biggest questions that I got from sharing my JFDI system and my AI executive assistant system uh was the audit trail, like the self-learning part. Um, and so I want to show you a couple of pieces of that. Um, and what's fun is I I'm going to start by showing you how this started and and really kind of how I learned this was going to work and how I kind of inadvertently built a very very simple but very very powerful memory system that I'm now adapting into what I would call a proper memory system. But this has been working so so well um that I don't want people to think that you have to do a fancy database memory system with vector search and all that stuff to get the power. So, um, the way I set things up, and I set this up pretty early, like in the first couple of weeks of building the system, once I had a handful of agents and commands that I was using on a daily basis, I wanted to um have them learn from patterns in usage. And so, the way I did that is there's sort of two main pieces here and they're they're nested. And this is like a bigger sort of design concept that um I have a lot of includes. You know, one of the issues with context management is loading, you know, really big files and some of my agents and slashcomands are pretty big. Um but making it so that it can progressively load through included files is really what's happening here. So every single agent and command including the main agent, so this is my claude.md as well. It has some version of this important statement that tells it to read the agent startup. Actually, there's two different versions. There's a startup and a startup quick. They work basically the same way. Um, the quick one works well in some of my agents because they kind of get spun up. They do a single task and then they hand off what they gather. Um, and so the quick one is fine for a more robust workflow. Um, like for instance, my morning overview. Where's my overview? um like my overview command is enormous. It's like what is this 1500 lines? So there's a lot going on to make sure that this one works all the time. Um but part of that, a big part of that is actually that before it does anything, it includes this agent startup checklist. And you'll see the very first thing in the agent startup checklist is the audit trail creation requirements. And that tells it uh after any workflow operation it's got to create an audit trail the where to save it and the structure. So it's going into an audit folder. Uh every day gets a new folder and then inside of it it is a bunch of files usually the agent name and then an activity markdown. Uh and then there is a specific template of the sort of structure and framework of what goes in there and then uh when and why but we're going to go into that implementation file. Um this is really kind of at the heart of what makes the audit trail system work on the generating side. So again every agent ends up here and then before it's done it is required to uh write a file that provides visibility into what happened decisions that were made um data for the strategic adviser which is another agent that comes along and notices opportunities within um the rule set that I gave it. So this where a lot of the proactive stuff comes from is from the strategic adviser um and so on and so forth. And when I originally started this this trust through transparency is like a core value of the system where I design things to provide me maximum transparency and then as a byproduct of that that transparency becomes value to both me and the system. Um so effectively what's happening is this rule set has it come through and say you know what happened what actions were taken what decisions were made within context what options were considered. That's a really interesting one because a lot of times I'm asking the system, hey, what are my options and how do I trade them off and so it does that too and then does it autonomously which is pretty amazing. Um, you know, data for data analysis files that were created cross agent notes is super helpful for when especially like that morning overview is a great one because I've got a relationship manager, a task orchestrator and a strategic adviser and actually a few that run in parallel to each other and so while they're running they're not necessarily talking to each other. I've seen people do this with, you know, agent mail and some other ways. This is I don't feel like I need extra infrastructure to make this work. Um, it kind of hashtag just happens. Um, here are some like data integrity parts. Um, where it says these are the things that need to be in every file. It is still an LLM and so like it follows these rules well, not perfectly. And so there's another TypeScript validator that comes through um I think once a day or maybe it's a little less often where it's basically checking data integrity and quality. I I shared a video of um uh if you go uh on I think I posted on LinkedIn and on Twitter the the quality audit of the files generated by this. And so that is a mix of again deterministic TypeScript and a rule set where it will do an evaluation, look for improvements and then actually make those improvements. Quality standards where those are recommended and so on and so forth. And so this happens uh again basically with everything of consequence in the system for the last two months or so has been generating um a lot of useful information. And you can see every day there's a folder um and then inside that folder I've got you know individual commands like my beating processing every time it's doing research on a person uh which it uses my my inbox to do not the internet. So it is very very tightly scoped research about a person based on actual communication and the relationship that we have. Um that all gets logged. I'm not going to dox anybody. So go in there but you get the general drift and come in here you know here's a pattern. you see the the person researcher that's literally happening all like all the time in the system so you get a lot of those files um but outside of those what's a good example here you know activity this is a cool one where it processed a link I dropped in a YouTube link this was a raycast hidden features link um this is actually a really cool one because this is a small task that happens a lot um but it is noticing the decisions where to put things and things like that and then I have another um command called synthesize that I run this once a week. Right now it's still a manual step, but I could just as easily make it a automated one and it could happen more or less often. I'm still kind of play like the reason it's manual is I'm playing with the quality of the results based on how many audits it needs to get good results. Um, but what this does is it looks at all the audit trails, looks at past synthesis, looks at my daily briefs. Um, and there's another pattern tracker uh, agent that runs around just looking for things that happened as a pattern. Um, and it synthesizes all of that. And, and basically what this comes down to is, and it's also using commit history, which has been amazing how much not everything hits git now that I have more things in a database, but you get so much value out of that. look at the audit trails running the pattern miner agent running the recommendation tracker agent system gap detector agent is another one where it goes hey these two things are happening and they're fine but if they talk to each other both of them will be better so it's going to notice that and and suggest improvements to the system uh crossweek analysis and then it generates a weekly synthesis if I do get an idea of what that looks like you know one of my most recent ones this is from a week ago Uh, and you can see that it is tracking weekly patterns cross week and it is also paying attention to whether or not I implement its recommendation. So, basically, it comes in here and says, this is oversimplified, but the goal here was to have it say, hey, you did this the la this certain way the last three times. Do you want to just make that an SOP so I don't have to guess each time and potentially guess wrong? Um, and so this goes through, it looks at all those patterns, assigns them a confidence score, which is what these percentages are. Um, and some of these are my noticing patterns in my behavior decisions. Some are patterns in the systems that we've built and how they're working or not, errors that they throw, sort of what's happening. And it's wild what it picks up, especially again with with the fact that it's reading my Git uh history. It's able to pick up like technical velocity, which is wild. Um, and then it makes recommendations and it basically puts those into my queue for things that I may want to build. Um, and loads up it basically helps sort them by things like readiness and potential impact and how much it'll break the system. So, this is a pre-sophisticated memory system with no vector search. Um uh and it is really geared towards turning actions that are repeated into consistent patterns to make sure they stay consistent, right? Um but it also allows a lot of space for emergent recommendations. And like I don't know what the number is. I could probably ask it what percentage of features grew out of this system. And if I had to ballpark it, it's it's probably somewhere near a third where it's like, hey, if we built this feature or we updated this feature in this way, this problem would go away or this opportunity would be greater. And that's a I've never worked with anything quite like that, a human or um uh software. I mean, humans obviously I work with creative people all the time and they suggest things. Um but I've never worked with somebody who does it so systematically and consistently. Um, and I feel like there's a lesson in there somewhere for people who are trying to like stand out at work. Um, because this is truly blowing my mind. So that is how the current audit trail system works at a very high level. Um, and basically when things graduate out of here, they end up in my SOPs which is at this is at the system level. Basically this docsed section um is everything from particular uh patterns and standards for development. Um it is various bits of system reference documentation on subsystems like it is the most thorough documentation for anything I've ever made. Um because this thing is really good at documenting things. Um it's basically documentation all the way down. So, uh, that is what it looks like. Has been running for a while. I just gave it an upgrade and that upgrade is pretty cool. Um, it looks like this. Give this quick refresh so you can see. And all right. So the way this works is I am now so my claud sessions file. So every time you type into claude code it's logging everything locally. Um basically every session all the things you message all the agent messages all the tool calls all the file touches all that stuff gets saved to a JSON file. It's I guess technically JSON L um because it's long. I don't actually know what JSON L is for. Um those take up a lot of spa. They don't take a lot of space in the hard drive. actually clawed code. If yours is slow starting up and you've been using it for a while, it's because it's parsing all of those when you load it up. So, I have those cleaned up about once a week. I might end up cleaning up a little bit more often. But regardless of the cleanup, the reason I can clean them up confidently is I'm shoving them right into my database. And so, I have this giant searchable database of every session. Uh you can see almost 2,000 sessions. And now these 2,000 sessions are things like me talking to it uh and working with it. but it also includes things like agent runs and commands that are automated. Um so it's stuff that doesn't include my direct um like invocation or interaction are is in here too. And again totally searchable organized by um and this is like the system guesses these and it's not 100% right but it's not super important that it is at least not yet. um uh whether or not it is classified basically means uh classification I have a little thing if I come in here and I open it up I can say classify with haiku and oh that's a big one so I'm not going to do that one there let's do it with a smaller one uh here's an internal task actually the memory catcher we're going to come back to the memory catcher in a second so I have this little button here and this appears in a few other places around the interface um like my my session picker and stuff like that basically it takes the transcript throws it at Haiku for a fairly cheap fast summary and it generates a nicer title than just the first line of the message. Um you know takes about the 15 or 20 seconds um uh here and session ended without user interaction. So it is really basing this on my interactions rather than its and that that actually might be a bug I want to fix. At any rate, uh what I just asked, so this is in a way your first line of defense when it comes to memory, right? These files contain everything. So I think of this is like longest term memory. It's everything that went back and forth. It's the highest resolution, but you generally it would be like the equivalent of remembering everything you ever said and everything everybody else anybody another person or co-orker or another person said. That's just not all that useful. So, um, and it's useful for reference, but in terms of like the day-to-day, you don't need access to all of that, but you do need access to moments of consequence is the way I think about it, right? So, the newest addition to the system is memories. And memories is a system that currently is set up in a job. And I'm still kind of like back like experimenting before I backfill my entire session. If I even decide to backfill the entire session, I haven't decided, but new new cla code sessions get inserted into the claude sessions table. And then another job comes along and looks at them and suggests uh or I should say extract. I didn't like the word the verb extract. I said let's make it catch memories. I was thinking about like dream catchers and memory catchers. So, what this does is it looks at the chat transcript for certain types of memorable moments. And those memorable moments include decisions, insights. Um, I'm not actually sure confidence means here, especially because there's just one. Um, notices patterns, notices commitments that I make, uh, notices learning moments, it notices corrections, which is not identical to learning. That cross agent thing, workflows, gaps are a cool one. Again, that's like two systems that are doing things that if they talk to each other um would be better. So, it automatically looks at every session and it catches the memories and it generates individual memories. You know, I think it's currently set, you know, it can generate as few as zero to one memory if there's anything of consequence. But there's also no upper bound like it is meant to go through and extract things. And so, this is going to take a little bit of tuning um of the exact prompt and stuff like that. But you can see the actual memories that it's generating. The timestamp here is not the time stamp of when the memory was quote unquote caught or generated by the LM. It is tied to when the original moment that was worth remembering gets saved. So this is basically pulling out that stuff and you can see some really interesting things. So without even clicking in here, you can see that this is a memory related to learning. Um it is categorized it as data. it has given it a confidence score of 85%. Its extraction it has also identified what it's calling entities um which is a noun right so that's any person in the system that's a business that I interact with um basically like almost anything that is a database entity has the potential to be linked here and it automatically links this memory to that entity. Why does that matter? Well, the last piece of this is using claude code hooks in a way where it can when I post something on the fly extract entities using the same rule set and then instantly look up the entities and any potential memories linked with them and contextually inject them along with whatever I type into the chat box. um so that I don't have to open up a new chat and give Claude code a bunch of context about what I'm working on. Um so I'm going to give you a concrete example and this is a live demo. Uh let's see if this actually works. So if I come up here and I'm going to start a brand new clean chat. Move my face out of the way. Uh and we're going to say uh tell me about my friend Dan. Now here's what I happen to know. I have multiple dans in the system. And if it works correctly pretty quickly, it should figure out that Dan is a person. It should hit the database, look up the potential Dan's, found them, both of them, and says, "Which one did you mean?" Because there's two, and it doesn't want to. One of my rules in the system is don't guess. If you're not 100% sure, verify. Um, so if I were to create another one, um, uh, let's see what's a good example here. So, um, all right, I happen to know that there's one here. It's like, uh, you know, when is the last time I talked to Kathy? Again, I didn't even give it a last name. I just first name. And obviously, the more information I give it here, the better. But previously, I would have to say a bunch of things about that person. And if we were in just in a chat session either earlier that day or even a couple of days ago, I'd have to kind of rebuild it all from the start. And this found that there's only one Kathy entity. It went and found the person file in the system, which includes the last contact. Um, and there you go. So, in this case, it wasn't the last time I talked to Kathy. It was that she was mentioned in an email about it. That's a little tweaking that I can do um because I did specify talk to Kathy versus she shows up anywhere in the system, but you get the drift. So thinking about memory in terms of like the longest term context which is those JSON L files, the uh useful caught memories and then the ability to look up memories that might or have a high likelihood of being relevant to the session that I just started. And it doesn't just do this at the top of a new session. It'll do it anywhere in the session. It's going to extract memories and it's going to keep doing it. So this is brand new. I literally built this in the last 24 hours. Um, and it's it's pretty awesome. Um, and there's even this little thing that like if it extracts a memory, but it doesn't know, you know, there's it doesn't know where in the system it's it it represents like in this case, these are partners that we have. And so I have a file for Kenty Dods, who is a friend and a client, and it mentions Epic Web, but we don't have a standalone Epic Web entity yet. Um, and so I have to figure out what does that mean? Do I want to or not? And this lets me, you know, ignore it. I could type ahead to resolve it. Um, uh, it does the same thing with files. Basically, that means that if I'm talking about a particular problem area or something like that, it can look at the last time I talked about that problem area or part of the app or feature, whatever it is, and instead of having to scan for all the files, it can look at the last time we worked on this, what files did it touch, and save a bunch of time and tokens while doing it. So, again, this doesn't even have a vector search component to it. I had a great call with my buddy Joel Hooks this morning and a bunch of his uh crew from Egghehead. Um, and like Joel has some cool open source stuff that I'm going to try out as adding a vector layer to this and see what that unlocks because my last two attempts I'm pretty sure I was just doing vector stuff wrong. Um, but we'll see. That'll be an update in the future. So that is the evolution of a very powerful but also very simple textbased memory system and a much more sophisticated one that I'm kind of evolving it towards and my plan is to keep running them in parallel and at some point in the future I may merge them. I may keep them separate um uh if they generate notably different results um otherwise you know they'll end up being sort of one and the same. But I really do kind of like the simplicity of the beauty of the flat filebased one. So that's uh that's my update for the day.

## Minhas Anotações

