# Stop Getting Blocked: My "Escalating" Web Scraper Skill

## Fonte
- **Tipo:** video
- **Autor:** Unsupervised Learning
- **URL:** https://www.youtube.com/watch?v=QqCAuUC7Ypg
- **Duração:** 11 min
- **Data original:** 2025-12-10
- **Data captura:** 2026-01-11

## Conteúdo

Kind: captions Language: en Hey, what's up? So, I want to talk about a skill that I just created for web browsing. And it's basically a set of workflows that I've been using for quite a while now. And it's a four- tiered system. It goes from regular web fetch, which is the enthropic fetching tool for web data. Then it goes on to curl using custom headers. Then it goes to browser automation, which actually uses a browser like Chrome to actually do the work using something like Playright. And then you have the fourth tier, which is bright data. and that is actually the sponsor of the video. And you're probably thinking, well, okay, so he got sponsored, so he's going to do a video. Nope, this is actually the opposite. So, I was actually going to release this skill, which I have. It's already live on the personal AI repository, which we'll talk about later, but I was going to release that skill. So, I asked the team, hey, can you reach out to Bright Data and see if they'll actually give us some uh sponsor money for doing this? And they said yes. So, it is a sponsored video, but this is my actual workflow. This is what I use dayto-day. So being the fourth level here, which is kind of the main point of this whole thing, let me tell you about the company. So essentially what they are, they're a way of getting content, browsing content. This is publicly available content. It's not stuff that's like behind authentication or something like that, but it's lots of different ways of doing that. So like blocks, captions, again, this is for public data, right? Scrapers of different kind, LinkedIn, social media, chatbt. It's got a crawler API, which uh we're going to talk about because that's part of the MCP. It's got a custom scraper, SER API for actually doing search requests, getting the results back, data sets, browser API, functions, residential proxies, ISP proxies, like incredibly crazy stuff. Like, it's just got so much different stuff. So, we got the pricing here, which we're going to talk about a little bit later, but it's very approachable. So, scrolling down here, we've got different data feeds. We've got web access APIs. This part is incredible. So this proxy infrastructure is what makes the whole thing so cool. Right? Data is so powerful because when you send requests in, you're actually emitting out of their network, right? 150 million diverse IPs. They can come out of data centers, ISPs, mobile devices, right? And it's actual devices with real IPs with real browsers running on them because it's their actual infrastructure. This is installed legitimate software that they have the infrastructure for. And that's what we're actually using when we use the bright data service. And that's why, right? Because like Cloudflare or somebody or Aami or somebody might freak out if you're making a couple of different requests to like different sites or whatever or multiple pages on a site and you're coming out of your own IP address, right? And they're like, "Yeah, that doesn't look right." Well, if you come through bright data, it could be spread all over the place. So, that's one of the main features that makes this thing really, really powerful. All right. So, what I did was I created a blog post. And again, we also have this full skill for the skill that we're talking about here is available publicly in the PI repo, which we have a link in the description, but I'm also going to talk about down below. So, what the system does is a four tier system. It goes from the anthropic basic tool to curl with custom headers to browser automation using uh playright or whatever and then using only as the fourth level if the other ones don't work only escalates if it fails. That's what I love about this skill and that's why I use it all the time because if I make a request with the bright data skill, I say, "Hey, use bright data to do this." It will try here and if the answer comes back here, boom, success. It stops. No need to proceed. Okay. So, scrolling down here, this is Kai, Daniel's assistant. Daniel asked me to write a technical tutorial. So, Kai actually, my digital assistant here, wrote this whole blog post, this whole tutorial, and it steps through these four tiers, and those are the ones we just talked about. So, web fetch is the anthropic tool and this is essentially what the tool call looks like. Then we got curl with custom browser headers and this is what those headers look like and this is pretty good at getting the content you actually want assuming it's not outright blocking curl and these are some of the reasons why these are really good headers to include in such a request and some additional info here. Next one is browser automation. This is full JavaScript execution. This is using Chromium. So you're actually executing the JavaScript. You're getting the full DOM that kind of stuff. Downside is this is rather slow compared to all the other ones. And then the fourth tier is the bright data MCP which is the thing we're talking about here in the video. So scrape is markdown scrape batch search engine search engine batch are some of the tools that are available inside of the MCP. And if we come over here and we just go into Kai &gt;&gt; Kai here ready to go &gt;&gt; and we do MCP we're going to see bright data right there. And we're going to go into it and we're going to say view tools. And there they are. Those are the four tools that we just covered. All right. So, let's talk about installing this thing. It's pretty simple. You saw it was an MCP server. So, you go and you make your account first. You, you know, check out the documentation or whatever, but it's it's pretty simple. You do the install and then here's what it looks like. And if I were to do that, you would see my key, but other than that, I have the exact same config. Then you restart Cloud Code and then you could do exactly what I just did for/mcp and you see uh what you have available. So, the progressive flow is exactly what I showed in the image above. It starts at level one and it proceeds all the way to level four. But if it works at a level before four, it just gives you the results then. And that that's why I like it and I tend to use it instead of just saying get or fetch or anything like that. I just say use the bright data skill timing. Those are roughly accurate there. Some examples here. Lots of different examples of like complex requirements. But let's look at the real world use cases. First of all, just a basic request. Use the bright data skill to fetch the homepage of my blog. So this should activate a skill first and foremost. Bright data skill is running. That's a good sign. Four tier scraping workflow to execute progressive escalation strategy. That is the cool part of this. Okay. Workflow is loaded starting with tier one web fetch. Exactly as we talked about in the docs here. Kai already has the context of what the site is. It's going to get it. It gets a 200. So it's probably going to say it worked at level one. Blog homepage fetch successfully using tier one web fetch in 3 seconds. &gt;&gt; There we go. So that's an example of tier one working. Okay, let's try tier two. Just jump to tier two and see if that would work as well. Just kind of curious. The site is behind Cloudflare. Curious if curl will work. Encoding issue. &gt;&gt; Tier 2 curl with Chrome header successfully validated on blog homepage. &gt;&gt; Okay, so in this case curl even worked likely because of those headers. I think if you would have done a basic curl request probably would not have worked. And we can even do tier three. Okay, see if tier three would work. Yeah, in this case, it needs to create a script to go do that in playright and then it executes the script. So, there are multiple reasons why tier three is not my favorite because most things should either work at level one or two. And if they don't, that's the reason I'm using this skill. You just jump right to four. And this is using headless. So, it shouldn't pop up a window. Should just do it quietly and go and do it and come back and say, "Yep, we got the content." &gt;&gt; Tier three browser automation confirmed working. JavaScript rendering successful in 6 seconds. &gt;&gt; Okay. And if we jump to the fourth tier, which is the bright data tier, I'm going to say use the bright data skill and go to the fourth tier. And let's just get everything from the blog page and uh scrape that and let me know if it works. Yep, that's right. /blog. Yeah. So, it's mentioning captions. It's mentioning using real IP addresses from the residential proxy network. &gt;&gt; Tier four bright data scraping successful on blog page. &gt;&gt; Nice. Oh, and it's actually got some data there which shows it actually went got it. So, that's just a couple use cases of like, okay, let's see it actually work or whatever. But what are some real world use cases like when would you want to use this? So, one would be Japanese e-commerce. What does that mean? Well, it means sometimes my partner wants like a sunscreen or a skin cream or something from Japan. And sometimes you can't go to like the Amazon site in Japan. So, we can come over here and we can say, "Hey, use bright data to get the front page of the Japanese Amazon site. Tell me what one of the most interesting products is or the recommended one or the most popular or whatever. Going to use a lot of context reading the Amazon page. That's fine. There's ways around that. &gt;&gt; Amazon Japan successfully scraped with bright data tier 4. &gt;&gt; Yeah, look at this. And now we got results. Font is only this big because we are making a video. But yeah, Jackaryi portable power station. Ooh, I saw this in a YouTube video recently actually. Power Station 1000 new. Unrelated, but I might actually have to check out that product. And it was specifically a Jackaryi one. It was a Korean blogger that was doing a camping video. Anyway, that's one use case. Yeah, let's clear that out because that was a lot of context. And let's look at some more use cases here. Use case two, cyber security defense investigation. So, yeah, this is a big one. This is a big one. So, if you're being attacked by attackers and you're in cyber security like I am, when you want to go investigate and see what their infrastructure is, see what their websites are, want to do that anonymously. You don't want to be going as your company or your personal, you know, home address or whatever. So, it's good to use a system like this to bounce from multiple locations and actually basically be anonymous as a result of that. When they look up that traffic, they're just going to see a bunch of random IPs and know that you're using a system like this. Bypassing overeager reverse proxies. So, sometimes Cloudflare freaks out and it won't let you look at a website you're supposed to be able to look at. Well, you can just say use bright data to go look at that website and you will get the content. So, those are like the main use cases that I use it for is like a proxy is freaking out. It doesn't work right. You can't get to it. There's some sort of weird restriction. You're not sure exactly what's wrong. You can't tell if the internet is glitching or whatever. Boom. I just say use bright data 2. Use bright data 2. And when I say that keyword, it spawns the skill. The skill goes and it goes through all four levels until it gets the stuff that I want. All right. So, back at the top here, one thing you might be wondering, sounds expensive. Why would you use that skill when it could end up costing you money? And the answer is it doesn't cost you much money at all. Yeah. Let's go to the pricing. So the pricing is ridiculous. It is so cheap to do this, right? Cost extremely reasonable for typical usage. So this is actually mine. This is a screenshot I had Kai put in here. So last few days I've used it. 31 cents. 31. And that is a whole lot of requests that I've used. If I were to go crazy with this thing, it would be a few dollars a month. So unless you have a business where you're like your whole business is, you know, putting millions of requests through a system, that might cost some money. Even then, it would be competitive cuz I did research about that for a different business as well. And it would still be competitive there, but that's not what I'm using it for. What I'm using it for is this skill that I use every day inside of Kai, inside of Cloud Code to just browse and get stuff, maybe look at some other geos, maybe bypass some basic stuff that's just annoying that doesn't involve authentication and doesn't involve like crazy bandwidth or throughput. So that's basically my use case. All right. And finally, last part of this is this is all available as a public skill. So the entire system is available as a public skill that you could just go and download now. And it's under this personal AI infrastructure repository and that is this system right here. You just click on here in the blog post which is also in the what's it called? And look at this. We go to claude. We go to skills and we go to brightite data and you're inside the same exact system that I am in over here. Four tier web scraping. It's got the documentation. It's got how to install it. It's got all the stuff that I just showed you. So, head over here and go get the skill. And again, you can use it in any platform. You could use it in I mean, it's Markdown, right? So, you could use it in Gemini, you could use it in Codeex, you could use it in whatever you want to use it for. You can even build your own from scratch system and use it in there. So, go download it, go use it. And thanks to Bright Data for sponsoring the video. And we will see you in the next

## Minhas Anotações

