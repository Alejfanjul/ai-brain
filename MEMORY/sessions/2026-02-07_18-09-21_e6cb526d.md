---
session_id: e6cb526d-43c2-434a-b6fa-3304b327699e
timestamp: 2026-02-07T18:09:21-03:00
project: ai-brain
cwd: /home/alejandro/ai-brain
source: agent
---

# Session e6cb526d

**Date:** 2026-02-07 | **Project:** ai-brain

## Summary

Sessão focada em implementar speech-to-text com Whisper. Partimos de "como usar Whisper?" e chegamos num plano estratégico com código pronto. Avaliamos 7 ferramentas desktop, descartamos todas por serem becos sem saída, e decidimos construir direto com a Whisper API da OpenAI — alinhado com o sistema-os (Python/FastAPI) para reuso futuro.

## What Was Done

- Pesquisa de 7 ferramentas de dictation (Buzz, OpenWhispr, whisper-key-local, WhisperTyping, Wispr Flow, Whisper_SST, Win+H)
- Tentativa de instalar OpenWhispr no Windows — falhou (precisa Visual Studio Build Tools)
- Decisão estratégica: construir com Whisper API direto em Python (não usar tools desktop)
- Análise profunda da arquitetura do sistema-os para validar alinhamento
- Criação do tool `whisper-dictation` em `ai-brain/tools/whisper-dictation/`:
  - `transcribe.py` — core reusável (Whisper API call)
  - `dictation.py` — wrapper desktop (toggle hotkey + mic + paste)
  - `config.json`, `requirements.txt`, `setup-windows.bat`, `README.md`
- Documentação do projeto em `projects/speech-to-text/README.md`
- Python 3.14.0a3 instalado no Windows
- API key da OpenAI criada e configurada via `setx`
- Clone do OpenWhispr em `C:\Users\Alejandro\openwhispr` (pode ser removido)

## Decisions Made

- **Whisper API (cloud) sobre modelo local**: Custo irrisório (~R$0.03/min), portável, sem GPU requerida
- **Python sobre Node.js**: sistema-os é FastAPI/Python — core `transcribe.py` migra direto
- **Toggle hotkey sobre hold-to-record**: Mais confortável pro dia a dia
- **Construir próprio sobre usar tool terceira**: Ferramentas desktop não servem pro plano maior (sistema-os POPs, app mobile)
- **Separação core/wrapper**: `transcribe.py` (reusável) vs `dictation.py` (desktop-only)

## Files Modified

- `tools/whisper-dictation/transcribe.py` (criado)
- `tools/whisper-dictation/dictation.py` (criado)
- `tools/whisper-dictation/config.json` (criado)
- `tools/whisper-dictation/requirements.txt` (criado)
- `tools/whisper-dictation/setup-windows.bat` (criado)
- `tools/whisper-dictation/README.md` (criado)
- `projects/speech-to-text/README.md` (criado)

## Learnings

- Win+H do Windows é péssimo em pt-BR (testado ao vivo)
- OpenWhispr precisa de Visual Studio Build Tools pra compilar no Windows — não tem installer pronto
- Wispr Flow tem 2.8/5 no Trustpilot e Windows é segunda classe
- WSL2 com WSLg 1.0.71 tem suporte a áudio mas libs PulseAudio não vêm instaladas
- Python 3.14.0a3 é alpha — pode dar problema com libs (sounddevice, keyboard)
- sistema-os já tem padrão de AI keys (ANTHROPIC_API_KEY) e pode receber OPENAI_API_KEY facilmente

## Next Steps

- Reiniciar terminal do VSCode (OPENAI_API_KEY via setx precisa de terminal novo)
- Rodar `setup-windows.bat` para instalar dependências
- Testar dictation: hotkey → falar em pt-BR → texto no cursor
- Se Python 3.14 alpha der problema → instalar 3.13
- Limpar `C:\Users\Alejandro\openwhispr` (tentativa abandonada)
- Futuro: migrar `transcribe.py` para sistema-os como TranscribeService

---
*Session summary by Claude (/fim)*
